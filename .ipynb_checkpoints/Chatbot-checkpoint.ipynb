{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fac9612-f230-4259-8fe5-1a70f10c5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.tools import Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1dbaa53d-4afe-4686-887a-bdafcd610058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"Medicines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49828431-91f7-48b0-83ab-defa0cced9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16aa0203-0502-4d0c-8427-9e1f236506d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to DB: ChatbotFarmacia on localhost...\n",
      "Loading data...\n",
      "Successfully loaded 627 rows.\n",
      "Data split into 126 chunks.\n",
      "Attempting to connect to ChatbotFarmacia on localhost...\n",
      "Successfully connected to database 'ChatbotFarmacia' on 'localhost'.\n",
      "SQLAlchemy engine created.\n"
     ]
    }
   ],
   "source": [
    "# --- Database Connection Details ---\n",
    "SERVER_NAME = \"localhost\"\n",
    "DATABASE_NAME = \"ChatbotFarmacia\" # <-- Good, you've set your DB name\n",
    "TABLE_NAME = \"Medicines\" # Note: TABLE_NAME here isn't used for the engine itself\n",
    "SCHEMA_NAME = \"dbo\"      # Note: SCHEMA_NAME here isn't used for the engine itself\n",
    "driver = \"ODBC Driver 17 for SQL Server\"\n",
    "connection_string = f\"mssql+pyodbc://{SERVER_NAME}/{DATABASE_NAME}?driver={driver}&trusted_connection=yes\"\n",
    "\n",
    "\n",
    "# --- Create Engine & Load Data ---\n",
    "df = pd.DataFrame()\n",
    "chunks = []\n",
    "try:\n",
    "    print(f\"Connecting to DB: {DATABASE_NAME} on {SERVER_NAME}...\")\n",
    "    engine = create_engine(connection_string)\n",
    "    sql_query = f\"SELECT * FROM [dbo].[Medicines]\" # Or your relevant query\n",
    "    print(f\"Loading data...\")\n",
    "    df = pd.read_sql(sql_query, engine)\n",
    "    print(f\"Successfully loaded {len(df)} rows.\")\n",
    "\n",
    "    # --- Split DataFrame into Chunks ---\n",
    "    # This line creates the 'chunks' variable needed below\n",
    "    chunks = [df.iloc[i:i+5] for i in range(0, len(df), 5)]\n",
    "    print(f\"Data split into {len(chunks)} chunks.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data or creating chunks: {e}\")\n",
    "# --- Create Database Engine ---\n",
    "try:\n",
    "    print(f\"Attempting to connect to {DATABASE_NAME} on {SERVER_NAME}...\")\n",
    "    engine = create_engine(connection_string)\n",
    "    # Optional connection test\n",
    "    connection = engine.connect()\n",
    "    print(f\"Successfully connected to database '{DATABASE_NAME}' on '{SERVER_NAME}'.\")\n",
    "    connection.close()\n",
    "    print(\"SQLAlchemy engine created.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to database: {e}\")\n",
    "    # Handle error\n",
    "    exit()\n",
    "\n",
    "# --- The 'engine' variable created above is what you need for the SQL Agent ---\n",
    "\n",
    "include_tables = [\"Medicines\", \"inventory\", \"inventory_chorrera\", \"inventory_costa_del_este\", \"inventory_david\", \"inventory_el_dorado\", \"inventory_san_francisco\",  \"Stores\"] # List all tables\n",
    "db = SQLDatabase(engine=engine, schema=\"dbo\", include_tables=include_tables)\n",
    "# Optional: print(db.get_table_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "644935d4-e098-45bd-a3ca-686adca45a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Agent created successfully.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=MODEL, temperature=2) # Low temp recommended for agent logic\n",
    "\n",
    "# Add this import line, typically near the top with your other imports\n",
    "\n",
    "\n",
    "# --- Your existing code ---\n",
    "# llm = ChatOpenAI(...)\n",
    "# db = SQLDatabase(...)\n",
    "# --- End of existing code ---\n",
    "\n",
    "# Now you can create the agent (this line should work after the import)\n",
    "sql_agent = create_sql_agent(\n",
    "    llm=llm, \n",
    "    db=db, \n",
    "    agent_type=\"openai-tools\", \n",
    "    verbose=True,\n",
    "    prefix=\"\"\"You are an expert SQL agent for a pharmacy system. \n",
    "    \n",
    "    You have access to tables including 'Stores' which contains store location information. \n",
    "    \n",
    "    When asked about stores, store counts, or locations, always query the Stores table.\n",
    "    When asked \"how many stores\", run 'SELECT COUNT(*) FROM dbo.Stores'.\n",
    "    \n",
    "    Always check the schema carefully before answering and provide clear, concise responses.\n",
    "    \"\"\"\n",
    ")\n",
    "print(\"SQL Agent created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e63ca45-947a-4acb-b9ef-e4e56d473039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 5 stores into DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# --- Load the DataFrame (ensure this is done before running the agent) ---\n",
    "try:\n",
    "    # Define the SQL query to fetch data from the \"Stores\" table\n",
    "    query = \"SELECT StoreID, StoreName, Location FROM dbo.Stores\" # Select only needed columns\n",
    "\n",
    "    # Execute the query and load the result into a DataFrame\n",
    "    # Ensure 'engine' is correctly initialized with your DB connection\n",
    "    stores_df = pd.read_sql(query, engine)\n",
    "    print(f\"Successfully loaded {len(stores_df)} stores into DataFrame.\")\n",
    "    # Keep only the DataFrame in memory, maybe close the engine if not needed elsewhere\n",
    "    # engine.dispose()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading stores data: {e}\")\n",
    "    # Handle the error appropriately, maybe exit or use dummy data\n",
    "    stores_df = pd.DataFrame() # Create an empty DataFrame to prevent errors later\n",
    "\n",
    "# --- Make sure stores_df is accessible globally or passed correctly ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "289b7d59-0b62-45ad-ba85-e6a0657cd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the models/LLMs first\n",
    "llm = ChatOpenAI(model=MODEL, temperature=0.7)\n",
    "agent_llm = ChatOpenAI(model=MODEL, temperature=0)\n",
    "\n",
    "# 2. Make sure your vectorstore already exists\n",
    "# If not, you need to recreate it:\n",
    "# Assuming 'db_name' is already defined and 'docs' contains your document objects\n",
    "# with proper side effects data in the page_content\n",
    "if 'vectorstore' not in locals() or vectorstore is None:\n",
    "    # Load existing vectorstore\n",
    "    print(\"Loading existing vectorstore from disk...\")\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    try:\n",
    "        vectorstore = Chroma(persist_directory=db_name, embedding_function=embeddings)\n",
    "        print(f\"Loaded vectorstore with {vectorstore._collection.count()} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading vectorstore: {e}\")\n",
    "        # You might need to recreate it if it doesn't exist\n",
    "        # vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=db_name)\n",
    "\n",
    "# 3. Set up the retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 4. Set up the memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# 5. Create the conversation chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=retriever, \n",
    "    memory=memory,\n",
    "    chain_type=\"stuff\",\n",
    "    combine_docs_chain_kwargs={\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=\"\"\"You are an expert pharmaceutical assistant. Use the following context to answer the question.\n",
    "            \n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "If you're asked about side effects, focus on the information in the 'Side Effects (Common)' and 'Side Effects (Rare)' fields.\n",
    "If you're asked about stores or inventory, explain that this information needs to be queried from the database.\n",
    "Answer the question based only on the provided context. If the information isn't available, say so clearly.\"\"\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# 6. Define the tool functions\n",
    "def vector_search(query):\n",
    "    result = conversation_chain.invoke({\"question\": query})\n",
    "    return result[\"answer\"]\n",
    "\n",
    "# Change this line in your sql_query function\n",
    "def sql_query(query):\n",
    "    try:\n",
    "        return sql_agent.invoke({\"input\": query})[\"output\"]  # Use Copysql_agent instead\n",
    "    except Exception as e:\n",
    "        return f\"Error querying database: {str(e)}\"\n",
    "\n",
    "# 7. Create tools\n",
    "from langchain.tools import Tool\n",
    "\n",
    "vector_search_tool = Tool(\n",
    "    name=\"MedicineInfoTool\",\n",
    "    func=vector_search,\n",
    "    description=\"Use this for questions about medicine properties, side effects, dosage, and general drug information.\"\n",
    ")\n",
    "\n",
    "sql_search_tool = Tool(\n",
    "    name=\"StoreAndInventoryTool\",\n",
    "    func=sql_query,\n",
    "    description=\"Use this for questions about stores, inventory, stock levels, locations, number of stores, and any store-related information.\"\n",
    ")\n",
    "\n",
    "# 8. Initialize the agent\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[vector_search_tool, sql_search_tool],\n",
    "    llm=agent_llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Improved chat function with better routing\n",
    "def chat(question, history):\n",
    "    # For store-related questions, directly route to SQL agent\n",
    "    if any(keyword in question.lower() for keyword in [\"store\", \"stores\", \"location\", \"locations\", \"inventory\", \"stock\", \"how many\"]):\n",
    "        try:\n",
    "            print(f\"Routing to SQL agent: {question}\")\n",
    "            return sql_agent.invoke({\"input\": question})[\"output\"]\n",
    "        except Exception as e:\n",
    "            print(f\"SQL direct routing failed: {e}, falling back to agent\")\n",
    "    \n",
    "    # For medicine-related questions about side effects, use vector search\n",
    "    if any(keyword in question.lower() for keyword in [\"side effect\", \"medicine\", \"drug\", \"medication\"]):\n",
    "        try:\n",
    "            print(f\"Routing to vector search: {question}\")\n",
    "            return vector_search(question)\n",
    "        except Exception as e:\n",
    "            print(f\"Vector search failed: {e}, falling back to agent\")\n",
    "    \n",
    "    # Otherwise, use the regular agent path\n",
    "    try:\n",
    "        print(f\"Using general agent: {question}\")\n",
    "        response = agent.invoke({\"input\": question})\n",
    "        return response[\"output\"]\n",
    "    except Exception as e:\n",
    "        return f\"I encountered an error: {str(e)}. Please try rephrasing your question.\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6dd8e5c-e4fb-4795-a2ec-214b9a5102fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_store_count() -> str:\n",
    "  \"\"\"\n",
    "  Use this tool ONLY when asked about the total number, count, quantity, or amount of store locations the company has.\n",
    "  Returns the total count as a string.\n",
    "  \"\"\"\n",
    "  global stores_df # Access the DataFrame (or pass it in if preferred)\n",
    "  if stores_df is None or stores_df.empty:\n",
    "      return \"I cannot access the store data right now to determine the count.\"\n",
    "  num_stores = len(stores_df)\n",
    "  return f\"There are currently {num_stores} store locations.\"\n",
    "\n",
    "# Create a list of tools for the agent\n",
    "tools = [get_store_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ceb0b73b-5ce8-4750-82b4-2302ac947de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreID       StoreName        InventoryTableName  \\\n",
      "0        1        Chorrera        inventory_chorrera   \n",
      "1        2  Costa del Este  inventory_costa_del_este   \n",
      "2        3           David           inventory_david   \n",
      "3        4       El Dorado       inventory_el_dorado   \n",
      "4        5   San Francisco   inventory_san_francisco   \n",
      "\n",
      "                       Location  \n",
      "0    Panamá Oeste - La Chorrera  \n",
      "1  Panama City - Costa del Este  \n",
      "2              Chiriquí - David  \n",
      "3       Panama City - El Dorado  \n",
      "4   Panama City - San Francisco  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the SQL query to fetch data from the \"Stores\" table\n",
    "query = \"SELECT * FROM dbo.Stores\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "stores_df = pd.read_sql(query, engine)\n",
    "print(stores_df.head())  # Print the first few rows to inspect the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4bef5937-ce13-4f6c-8020-56b3c746a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting document conversion (translating 1/0 status to text in page_content)...\n",
      "Created 627 Document objects with updated page_content.\n"
     ]
    }
   ],
   "source": [
    "# --- Corrected Document Creation Loop (Option 1) ---\n",
    "# Assuming 'chunks' is your list of DataFrames from the SQL query\n",
    "# Requires: from langchain.docstore.document import Document\n",
    "\n",
    "docs = []\n",
    "print(\"Starting document conversion (translating 1/0 status to text in page_content)...\")\n",
    "for i, chunk_df in enumerate(chunks):\n",
    "    for index, row in chunk_df.iterrows():\n",
    "        try:\n",
    "            # --- Get the numeric status (assuming column name is 'Prescription') ---\n",
    "            try:\n",
    "                 # Use the actual column name from your SQL table if different from 'Prescription'\n",
    "                 status_flag = int(row.get('Prescription', -1)) # Get 1, 0, or -1\n",
    "            except (ValueError, TypeError):\n",
    "                 status_flag = -1 # Handle non-numeric or missing data\n",
    "\n",
    "            # --- Translate numeric status to text ---\n",
    "            if status_flag == 1:\n",
    "                status_text = \"Requires Prescription\"\n",
    "            elif status_flag == 0:\n",
    "                status_text = \"Over-the-Counter\"\n",
    "            else:\n",
    "                status_text = \"Unknown\"\n",
    "\n",
    "            # --- MODIFIED page_content to include the status TEXT ---\n",
    "            # Use correct column names from your SQL table (e.g., 'Generic Name', 'Uses')\n",
    "            page_content = f\"Medicine: {row['Generic Name']}\\nUses: {row['Uses']}\\nPrescription Status: {status_text}\"\n",
    "\n",
    "            # --- Metadata: Store the numeric flag and other relevant fields ---\n",
    "            metadata = {\n",
    "                \"source_db_table\": f\"{SCHEMA_NAME}.{TABLE_NAME}\", # Identify source\n",
    "                # Use primary key from DB if available and useful, otherwise use index\n",
    "                # \"db_primary_key\": row.get('YourPrimaryKeyColumn'),\n",
    "                \"chunk_index\": i,\n",
    "                # Store the numeric flag using a clear key name\n",
    "                \"prescription_required_flag\": status_flag,\n",
    "                # Add other relevant fields from your DB table, ensuring column names match\n",
    "                \"uses\": row.get('Uses', \"\"),\n",
    "                \"side_effects_common\": row.get('Side Effects (Common)', \"\"),\n",
    "                \"side_effects_rare\": row.get('Side Effects (Rare)', \"\"),\n",
    "                \"similar_drugs\": row.get('Similar Drugs', \"\"),\n",
    "                \"brand_name_1\": row.get('Brand Name 1', \"\"),\n",
    "                # ... etc\n",
    "            }\n",
    "            docs.append(Document(page_content=page_content, metadata=metadata))\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError processing row {index}: {e} - Check column names from DB query!\")\n",
    "        except Exception as e:\n",
    "             print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "print(f\"Created {len(docs)} Document objects with updated page_content.\")\n",
    "# --- End of Corrected Document Creation Loop ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7d29aab-8fec-470f-b5cb-f10d8da39ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "# Optionally, view the first chunk\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0c4cff5-35ac-42e3-b6e0-6ee30f881709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_count() -> str:\n",
    "  \"\"\"\n",
    "  Use this tool ONLY when asked about the total number, count, quantity, or amount of store locations the company has.\n",
    "  Returns the total count as a string.\n",
    "  \"\"\"\n",
    "  global stores_df # Access the DataFrame (or pass it in if preferred)\n",
    "  if stores_df is None or stores_df.empty:\n",
    "      return \"I cannot access the store data right now to determine the count.\"\n",
    "  num_stores = len(stores_df)\n",
    "  return f\"There are currently {num_stores} store locations.\"\n",
    "\n",
    "# Create a list of tools for the agent\n",
    "tools = [get_store_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e14a7c83-8fb9-41d5-9877-4b644f90120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection in 'Medicines'.\n",
      "Vectorstore created with 627 documents in 'Medicines'.\n"
     ]
    }
   ],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "embeddings = OpenAIEmbeddings() # Assumes 'from langchain_openai import OpenAIEmbeddings' was used\n",
    "                               # and the OpenAI API key is configured (e.g., environment variable)\n",
    "\n",
    "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
    "# Then replace embeddings = OpenAIEmbeddings()\n",
    "# with:\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete if already exists\n",
    "# Assumes 'db_name' variable (string path) is defined earlier\n",
    "# Assumes 'import os' and 'from langchain_chroma import Chroma' were used\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    try:\n",
    "        # Attempt to connect and delete the collection within the directory\n",
    "        Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "        print(f\"Deleted existing collection in '{db_name}'.\")\n",
    "    except Exception as e:\n",
    "        # Handle cases where deletion might fail (e.g., directory exists but isn't a valid Chroma DB)\n",
    "        print(f\"Could not delete collection in '{db_name}': {e}\")\n",
    "\n",
    "# Create vectorstore\n",
    "# CRITICAL: Assumes 'docs' is a list of LangChain Document objects\n",
    "# It seems like 'docs' might still be undefined based on your previous error.\n",
    "# You need to convert your DataFrame chunks into Document objects first.\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=docs, # 'docs' needs to be List[Document]\n",
    "                                     embedding=embeddings,\n",
    "                                     persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents in '{db_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "99abe597-e50f-4aff-9678-385496262bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 1254 documents\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac0ef209-d389-4e1c-b437-ed923bf4dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,254 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35183586-51e9-4860-9caa-dd78d2190c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1254 items.\n",
      "First item metadata: {'brand_name_1': 'Nulojix', 'chunk_index': 0, 'prescription_required_flag': 1, 'side_effects_common': 'Hypertension, diarrhea, anemia', 'side_effects_rare': 'Post-transplant lymphoproliferative disorder, infections', 'similar_drugs': 'Basiliximab, Tacrolimus', 'source_db_table': 'dbo.Medicines', 'uses': 'Prevention of kidney transplant rejection'}\n"
     ]
    }
   ],
   "source": [
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings']) # Requires: import numpy as np\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "# doc_types = [metadata['doc_type'] for metadata in metadatas if metadata is not None] # REMOVED/COMMENTED\n",
    "# colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types] # REMOVED/COMMENTED\n",
    "\n",
    "# You can now work with vectors, documents, metadatas\n",
    "print(f\"Retrieved {len(vectors)} items.\")\n",
    "if metadatas:\n",
    "     print(\"First item metadata:\", metadatas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7c32b-3414-4e30-a59e-c092cf833cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume 'vectors' (numpy array) and 'documents' (list of strings) exist from collection.get()\n",
    "\n",
    "print(\"Running t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(vectors)-1)) # Added perplexity adjustment\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "print(\"t-SNE complete.\")\n",
    "\n",
    "# Create the 2D scatter plot (Simplified)\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=0.8), # Removed 'color=colors'\n",
    "    # Simplified hover text using index and document snippet\n",
    "    text=[f\"Index: {i}<br>Text: {d[:100]}...\" for i, d in enumerate(documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization (t-SNE)',\n",
    "    xaxis_title='t-SNE Component 1', # More specific axis titles\n",
    "    yaxis_title='t-SNE Component 2',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96015feb-b198-4fb7-8302-b87ca7d0f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume 'vectors', 'documents', 'metadatas' exist\n",
    "\n",
    "# --- Block to define colors (MUST RUN BEFORE PLOTTING) ---\n",
    "print(\"Defining colors based on metadata...\")\n",
    "# Line 57 visualization code - update to match what you defined earlier\n",
    "status_list = [metadata.get('prescription_required_flag', -1) for metadata in metadatas if metadata is not None]\n",
    "color_map = {1: 'red', 0: 'blue', -1: 'grey'}  # 1=prescription, 0=OTC, -1=unknown\n",
    "colors = [color_map.get(status, 'grey') for status in status_list]\n",
    "print(\"Colors defined.\")\n",
    "# --- End of color definition block ---\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42, perplexity=min(30, len(vectors)-1))\n",
    "print(\"Running 3D t-SNE...\")\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "print(\"3D t-SNE complete.\")\n",
    "\n",
    "# Create the 3D scatter plot (Using defined colors and status_list)\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=3, color=colors, opacity=0.7), # Use defined 'colors'\n",
    "    # Update hover text\n",
    "    text=[f\"Prescription: {s}<br>Text: {d[:100]}...\" for s, d in zip(status_list, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization (t-SNE by Prescription Status)',\n",
    "    scene=dict(xaxis_title='t-SNE Comp 1', yaxis_title='t-SNE Comp 2', zaxis_title='t-SNE Comp 3'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f37cc-a9e6-41f8-b0f8-a209bc2bd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model name as a string\n",
    "MODEL = \"gpt-4\"\n",
    "\n",
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# Alternative - if you'd like to use Ollama locally, uncomment this line instead\n",
    "# llm = ChatOpenAI(temperature=0.7, model_name='llama3.2', base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2975c79d-a1c7-49c6-9d6f-a6f869ef7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping that in a function\n",
    "\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d359efe-07e9-4d0c-923e-24685c5d4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12554609-0002-4404-8636-7c5e01a1c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's investigate what gets sent behind the scenes\n",
    "\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, callbacks=[StdOutCallbackHandler()])\n",
    "\n",
    "query = \"?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e955ca-b612-495f-84a9-87592ef5fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG; k is how many chunks to use\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a380d9-cf0b-4785-8209-f944037ce2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4222e-b06e-4731-b687-ea876e57d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9431ab8-6af8-4ad0-894d-9241cfb3c1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16c7bc-6972-4804-b34f-c4eca08edd08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
